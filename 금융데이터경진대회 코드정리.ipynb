{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d33afdf3",
   "metadata": {},
   "source": [
    "# 통합 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b58c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('C:/Users/HCJ/Desktop/2021_Summer/Finance_data/bank.csv')\n",
    "Y=data['TARGET']\n",
    "X=data.drop(['Unnamed: 0','TARGET'],axis=1)\n",
    "X.iloc[:,[42,43,44,63,64,65,66,67]] = X.iloc[:,[42,43,44,63,64,65,66,67]].astype('category')\n",
    "X.iloc[:,[42,43,44,63,64,65,66,67]]=X.iloc[:,[42,43,44,63,64,65,66,67]].replace([1,2],[0,1])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y,test_size=0.3,random_state=1004)\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "smote_nc = SMOTENC(categorical_features=[42,43,44,63,64,65,66,67], random_state=1004)\n",
    "X_smotenc, Y_smotenc = smote_nc.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e779ab01",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8ad0fc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.9928334402275453 \n",
      "\n",
      "   precision    recall    fscore  support\n",
      "0   0.992944  0.999888  0.996404  35608.0\n",
      "1   0.000000  0.000000  0.000000    253.0\n"
     ]
    }
   ],
   "source": [
    "#샘플링 미적용\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log=LogisticRegression(max_iter = 1000)\n",
    "log.fit(X_train,Y_train)\n",
    "Y_pred_log=log.predict(X_test)\n",
    "\n",
    "#성능평가\n",
    "from sklearn import metrics\n",
    "log_accuracy=metrics.accuracy_score(Y_test,Y_pred_log)\n",
    "log_score=metrics.precision_recall_fscore_support(Y_test,Y_pred_log)\n",
    "print('accuracy')\n",
    "print(log_accuracy,'\\n')\n",
    "log_score = pd.DataFrame(log_score).transpose()\n",
    "log_score.columns =[\"precision\", \"recall\", \"fscore\", \"support\"]\n",
    "print(log_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6b3092db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.8517609659518697 \n",
      "\n",
      "   precision    recall    fscore  support\n",
      "0   0.998519  0.851971  0.919442  35608.0\n",
      "1   0.037963  0.822134  0.072575    253.0\n"
     ]
    }
   ],
   "source": [
    "#샘플링 적용\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log=LogisticRegression(max_iter = 1000)\n",
    "log.fit(X_smotenc,Y_smotenc)\n",
    "Y_pred_log=log.predict(X_test)\n",
    "\n",
    "#성능평가\n",
    "from sklearn import metrics\n",
    "log_accuracy=metrics.accuracy_score(Y_test,Y_pred_log)\n",
    "log_score=metrics.precision_recall_fscore_support(Y_test,Y_pred_log)\n",
    "print('accuracy')\n",
    "print(log_accuracy,'\\n')\n",
    "log_score = pd.DataFrame(log_score).transpose()\n",
    "log_score.columns =[\"precision\", \"recall\", \"fscore\", \"support\"]\n",
    "print(log_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd97a0f",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ac64090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.9929449820138869 \n",
      "\n",
      "   precision  recall   fscore  support\n",
      "0   0.992945     1.0  0.99646  35608.0\n",
      "1   0.000000     0.0  0.00000    253.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HCJ\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#샘플링 미적용\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "t1=DecisionTreeClassifier(max_depth=4, min_samples_split=50, min_samples_leaf=25)\n",
    "t1.fit(X_train,Y_train)\n",
    "Y_pred_dt=t1.predict(X_test)\n",
    "\n",
    "#성능평가\n",
    "tree_accuracy=metrics.accuracy_score(Y_test,Y_pred_dt)\n",
    "tree_score=metrics.precision_recall_fscore_support(Y_test,Y_pred_dt)\n",
    "print('accuracy')\n",
    "print(tree_accuracy,'\\n')\n",
    "tree_score = pd.DataFrame(tree_score).transpose()\n",
    "tree_score.columns =[\"precision\", \"recall\", \"fscore\", \"support\"]\n",
    "print(tree_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bdddad80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.7400239814840635 \n",
      "\n",
      "   precision    recall    fscore  support\n",
      "0   0.998861  0.739019  0.849515  35608.0\n",
      "1   0.023434  0.881423  0.045655    253.0\n"
     ]
    }
   ],
   "source": [
    "#샘플링 적용\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "t1=DecisionTreeClassifier(max_depth=4, min_samples_split=50, min_samples_leaf=25)\n",
    "t1.fit(X_smotenc,Y_smotenc)\n",
    "Y_pred_dt=t1.predict(X_test)\n",
    "\n",
    "#성능평가\n",
    "tree_accuracy=metrics.accuracy_score(Y_test,Y_pred_dt)\n",
    "tree_score=metrics.precision_recall_fscore_support(Y_test,Y_pred_dt)\n",
    "print('accuracy')\n",
    "print(tree_accuracy,'\\n')\n",
    "tree_score = pd.DataFrame(tree_score).transpose()\n",
    "tree_score.columns =[\"precision\", \"recall\", \"fscore\", \"support\"]\n",
    "print(tree_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa944cac",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0d157d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.8327430913806084 \n",
      "\n",
      "   precision    recall    fscore  support\n",
      "0   0.995449  0.835374  0.908413  35608.0\n",
      "1   0.019568  0.462451  0.037548    253.0\n"
     ]
    }
   ],
   "source": [
    "#샘플링 미적용\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "catNB1=CategoricalNB()\n",
    "catNB1.fit(X_train,Y_train)\n",
    "Y_pred_nb=catNB1.predict(X_test)\n",
    "\n",
    "#성능평가\n",
    "naive_accuracy=metrics.accuracy_score(Y_test,Y_pred_nb)\n",
    "naive_score=metrics.precision_recall_fscore_support(Y_test,Y_pred_nb)\n",
    "print('accuracy')\n",
    "print(naive_accuracy,'\\n')\n",
    "naive_score = pd.DataFrame(naive_score).transpose()\n",
    "naive_score.columns = [\"precision\", \"recall\", \"fscore\", \"support\"]\n",
    "print(naive_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c0c9154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.7566994785421488 \n",
      "\n",
      "   precision    recall    fscore  support\n",
      "0   0.996381  0.757723  0.860816  35608.0\n",
      "1   0.017650  0.612648  0.034311    253.0\n"
     ]
    }
   ],
   "source": [
    "#샘플링 적용\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "catNB1=CategoricalNB()\n",
    "catNB1.fit(X_smotenc,Y_smotenc)\n",
    "Y_pred_nb=catNB1.predict(X_test)\n",
    "\n",
    "#성능평가\n",
    "naive_accuracy=metrics.accuracy_score(Y_test,Y_pred_nb)\n",
    "naive_score=metrics.precision_recall_fscore_support(Y_test,Y_pred_nb)\n",
    "print('accuracy')\n",
    "print(naive_accuracy,'\\n')\n",
    "naive_score = pd.DataFrame(naive_score).transpose()\n",
    "naive_score.columns = [\"precision\", \"recall\", \"fscore\", \"support\"]\n",
    "print(naive_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930d60d5",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f7dfbe14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.9929449820138869 \n",
      "\n",
      "   precision  recall   fscore  support\n",
      "0   0.992945     1.0  0.99646  35608.0\n",
      "1   0.000000     0.0  0.00000    253.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HCJ\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#샘플링 미적용\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=20, max_depth=5,random_state=0)\n",
    "clf.fit(X_train,Y_train)\n",
    "Y_pred_rf=clf.predict(X_test)\n",
    "\n",
    "#성능평가\n",
    "forest_accuracy=metrics.accuracy_score(Y_test,Y_pred_rf)\n",
    "forest_score=metrics.precision_recall_fscore_support(Y_test,Y_pred_rf)\n",
    "print('accuracy')\n",
    "print(forest_accuracy,'\\n')\n",
    "forest_score = pd.DataFrame(forest_score).transpose()\n",
    "forest_score.columns = [\"precision\", \"recall\", \"fscore\", \"support\"]\n",
    "print(forest_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b854bc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.8800646942360781 \n",
      "\n",
      "   precision    recall    fscore  support\n",
      "0   0.998662  0.880392  0.935805  35608.0\n",
      "1   0.047204  0.833992  0.089350    253.0\n"
     ]
    }
   ],
   "source": [
    "#샘플링 적용\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=20, max_depth=5,random_state=0)\n",
    "clf.fit(X_smotenc,Y_smotenc)\n",
    "Y_pred_rf=clf.predict(X_test)\n",
    "\n",
    "#성능평가\n",
    "forest_accuracy=metrics.accuracy_score(Y_test,Y_pred_rf)\n",
    "forest_score=metrics.precision_recall_fscore_support(Y_test,Y_pred_rf)\n",
    "print('accuracy')\n",
    "print(forest_accuracy,'\\n')\n",
    "forest_score = pd.DataFrame(forest_score).transpose()\n",
    "forest_score.columns = [\"precision\", \"recall\", \"fscore\", \"support\"]\n",
    "print(forest_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa7946d",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8888b9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.9929449820138869 \n",
      "\n",
      "   precision  recall   fscore  support\n",
      "0   0.992945     1.0  0.99646  35608.0\n",
      "1   0.000000     0.0  0.00000    253.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HCJ\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#샘플링 미적용\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10,10), activation='logistic', \n",
    "                    solver='sgd', alpha=0.01, batch_size=32,learning_rate_init=0.1, \n",
    "                    max_iter=500)  \n",
    "mlp.fit(X_train,Y_train)\n",
    "Y_pred_mlp = mlp.predict(X_test)\n",
    "\n",
    "#성능 평가\n",
    "mlp_accuracy=metrics.accuracy_score(Y_test,Y_pred_mlp)\n",
    "mlp_score=metrics.precision_recall_fscore_support(Y_test,Y_pred_mlp)\n",
    "print('accuracy')\n",
    "print(mlp_accuracy,'\\n')\n",
    "mlp_score = pd.DataFrame(mlp_score).transpose()\n",
    "mlp_score.columns = [\"precision\", \"recall\", \"fscore\", \"support\"]\n",
    "print(mlp_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dc173e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.8978277237109953 \n",
      "\n",
      "   precision    recall    fscore  support\n",
      "0   0.997973  0.898927  0.945864  35608.0\n",
      "1   0.049644  0.743083  0.093069    253.0\n"
     ]
    }
   ],
   "source": [
    "#샘플링 적용\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10,10), activation='logistic', \n",
    "                    solver='sgd', alpha=0.01, batch_size=32,learning_rate_init=0.1, \n",
    "                    max_iter=500)  \n",
    "mlp.fit(X_smotenc, Y_smotenc)\n",
    "Y_pred_mlp = mlp.predict(X_test)\n",
    "\n",
    "#성능 평가\n",
    "mlp_accuracy=metrics.accuracy_score(Y_test,Y_pred_mlp)\n",
    "mlp_score=metrics.precision_recall_fscore_support(Y_test,Y_pred_mlp)\n",
    "print('accuracy')\n",
    "print(mlp_accuracy,'\\n')\n",
    "mlp_score = pd.DataFrame(mlp_score).transpose()\n",
    "mlp_score.columns = [\"precision\", \"recall\", \"fscore\", \"support\"]\n",
    "print(mlp_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddec89d7",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron with bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a0c2a985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.9929449820138869 \n",
      "\n",
      "   precision  recall   fscore  support\n",
      "0   0.992945     1.0  0.99646  35608.0\n",
      "1   0.000000     0.0  0.00000    253.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HCJ\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#샘플링 미적용\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag_clf = BaggingClassifier(MLPClassifier(hidden_layer_sizes=(10,10), activation='logistic', \n",
    "                                          solver='sgd', alpha=0.01, batch_size=32,learning_rate_init=0.1, \n",
    "                                          max_iter=500),\n",
    "                           n_estimators=500,\n",
    "                           max_samples=100,\n",
    "                           bootstrap=True,\n",
    "                           n_jobs=-1)\n",
    "model = bag_clf.fit(X_train,Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#성능 평가\n",
    "mlpb_accuracy=metrics.accuracy_score(Y_test,y_pred)\n",
    "mlpb_score=metrics.precision_recall_fscore_support(Y_test,y_pred)\n",
    "print('accuracy')\n",
    "print(mlpb_accuracy,'\\n')\n",
    "mlpb_score = pd.DataFrame(mlpb_score).transpose()\n",
    "mlpb_score.columns = [\"precision\", \"recall\", \"fscore\", \"support\"]\n",
    "print(mlpb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "83fef625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.8069769387356739 \n",
      "\n",
      "   precision    recall    fscore  support\n",
      "0   0.998263  0.807010  0.892506  35608.0\n",
      "1   0.028693  0.802372  0.055404    253.0\n"
     ]
    }
   ],
   "source": [
    "#샘플링 적용\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag_clf = BaggingClassifier(MLPClassifier(hidden_layer_sizes=(10,10), activation='logistic', \n",
    "                                          solver='sgd', alpha=0.01, batch_size=32,learning_rate_init=0.1, \n",
    "                                          max_iter=500),\n",
    "                           n_estimators=500,\n",
    "                           max_samples=100,\n",
    "                           bootstrap=True,\n",
    "                           n_jobs=-1)\n",
    "model = bag_clf.fit(X_smotenc, Y_smotenc)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#성능 평가\n",
    "mlpb_accuracy=metrics.accuracy_score(Y_test,y_pred)\n",
    "mlpb_score=metrics.precision_recall_fscore_support(Y_test,y_pred)\n",
    "print('accuracy')\n",
    "print(mlpb_accuracy,'\\n')\n",
    "mlpb_score = pd.DataFrame(mlpb_score).transpose()\n",
    "mlpb_score.columns = [\"precision\", \"recall\", \"fscore\", \"support\"]\n",
    "print(mlpb_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099534b0",
   "metadata": {},
   "source": [
    "# Factorization Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fc64c85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.9929449820138869 \n",
      "\n",
      "   precision  recall   fscore  support\n",
      "0   0.992945     1.0  0.99646  35608.0\n",
      "1   0.000000     0.0  0.00000    253.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HCJ\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#샘플링 미적용\n",
    "import xlearn as xl\n",
    "import numpy as np\n",
    "# DMatrix transition, if use field ,use must pass field map(an array) of features\n",
    "xdm_train = xl.DMatrix(X_train,Y_train)\n",
    "xdm_test = xl.DMatrix(X_test, Y_test)\n",
    "\n",
    "# Training task\n",
    "fm_model = xl.create_fm()  # Use factorization machine\n",
    "fm_model.setTrain(xdm_train)    # Training data\n",
    "fm_model.setValidate(xdm_test)  # Validation data\n",
    "\n",
    "# param:\n",
    "#  0. regression task\n",
    "#  1. learning rate: 0.2\n",
    "#  2. regular lambda: 0.002\n",
    "#  3. evaluation metric: mae\n",
    "param = {'task':'binary', 'lr':0.03,\n",
    "         'lambda':0.0001, 'metric':'acc'}\n",
    "\n",
    "# Start to train\n",
    "fm_model.fit(param, './modeldm.out')\n",
    "\n",
    "# Prediction task\n",
    "fm_model.setTest(xdm_test)  # Test data\n",
    "fm_model.setSign() # Convert output to 0,1\n",
    "\n",
    "Y_pred_fm = fm_model.predict(\"./modeldm.out\")\n",
    "\n",
    "#성능 평가\n",
    "from sklearn import metrics\n",
    "fm_accuracy=metrics.accuracy_score(Y_test,Y_pred_fm)\n",
    "fm_score=metrics.precision_recall_fscore_support(Y_test,Y_pred_fm)\n",
    "print('accuracy')\n",
    "print(fm_accuracy, '\\n')\n",
    "fm_score = pd.DataFrame(fm_score).transpose()\n",
    "fm_score.columns = [\"precision\", \"recall\", \"fscore\", \"support\"]\n",
    "print(fm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b1b7eea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.8236245503471739 \n",
      "\n",
      "   precision    recall    fscore  support\n",
      "0   0.997959  0.824056  0.902709  35608.0\n",
      "1   0.029885  0.762846  0.057518    253.0\n"
     ]
    }
   ],
   "source": [
    "#샘플링 적용\n",
    "import xlearn as xl\n",
    "import numpy as np\n",
    "# DMatrix transition, if use field ,use must pass field map(an array) of features\n",
    "xdm_train = xl.DMatrix(X_smotenc, Y_smotenc)\n",
    "xdm_test = xl.DMatrix(X_test, Y_test)\n",
    "\n",
    "# Training task\n",
    "fm_model = xl.create_fm()  # Use factorization machine\n",
    "fm_model.setTrain(xdm_train)    # Training data\n",
    "fm_model.setValidate(xdm_test)  # Validation data\n",
    "\n",
    "# param:\n",
    "#  0. regression task\n",
    "#  1. learning rate: 0.2\n",
    "#  2. regular lambda: 0.002\n",
    "#  3. evaluation metric: mae\n",
    "param = {'task':'binary', 'lr':0.03,\n",
    "         'lambda':0.0001, 'metric':'acc'}\n",
    "\n",
    "# Start to train\n",
    "fm_model.fit(param, './modeldm.out')\n",
    "\n",
    "# Prediction task\n",
    "fm_model.setTest(xdm_test)  # Test data\n",
    "fm_model.setSign() # Convert output to 0,1\n",
    "\n",
    "Y_pred_fm = fm_model.predict(\"./modeldm.out\")\n",
    "\n",
    "#성능 평가\n",
    "from sklearn import metrics\n",
    "fm_accuracy=metrics.accuracy_score(Y_test,Y_pred_fm)\n",
    "fm_score=metrics.precision_recall_fscore_support(Y_test,Y_pred_fm)\n",
    "print('accuracy')\n",
    "print(fm_accuracy, '\\n')\n",
    "fm_score = pd.DataFrame(fm_score).transpose()\n",
    "fm_score.columns = [\"precision\", \"recall\", \"fscore\", \"support\"]\n",
    "print(fm_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcb71b0",
   "metadata": {},
   "source": [
    "# Field-aware Factorization Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "55685360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.9929449820138869\n",
      "   precision  recall   fscore  support\n",
      "0   0.992945     1.0  0.99646  35608.0\n",
      "1   0.000000     0.0  0.00000    253.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HCJ\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#샘플링 적용\n",
    "# 데이터 추가 전처리\n",
    "train = pd.concat([X_train,Y_train],axis=1)\n",
    "test = pd.concat([Y_test,X_test],axis=1)\n",
    "x = pd.concat([train,test])\n",
    "x = x.reset_index(drop=True)\n",
    "unwanted = x.columns[x.columns.str.startswith('ps_calc_')]\n",
    "x.drop(unwanted,inplace=True,axis=1)\n",
    "features = x.columns[2:]\n",
    "categories = []\n",
    "for c in features:\n",
    "    trainno = len(x.loc[:train.shape[0],c].unique())\n",
    "    testno = len(x.loc[train.shape[0]:,c].unique())\n",
    "# 카테고리 피쳐 전처리\n",
    "x.loc[:,'J_SIC_CD_5_RE'] = pd.cut(x['J_SIC_CD_5_RE'], 50,labels=False)\n",
    "x.loc[:,'J_SKIL_GDCD_RE'] = pd.cut(x['J_SKIL_GDCD_RE'], 50,labels=False)\n",
    "x.loc[:,'J_MAIN_LON_BANK_CD_RE'] = pd.cut(x['J_MAIN_LON_BANK_CD_RE'], 50,labels=False)\n",
    "x.loc[:,'P_PRIMARY_CUSTOM_FLG_RE'] =  pd.cut(x['P_PRIMARY_CUSTOM_FLG_RE'], 50,labels=False)\n",
    "x.loc[:,'P_ACT_CUSTOM_FLG_RE'] =  pd.cut(x['P_ACT_CUSTOM_FLG_RE'], 50,labels=False)\n",
    "x.loc[:,'P_TOT_LON_FLG_RE'] =  pd.cut(x['P_TOT_LON_FLG_RE'], 50,labels=False)\n",
    "x.loc[:,'P_INBK_JNNG_FLG_RE'] =  pd.cut(x['P_INBK_JNNG_FLG_RE'], 50,labels=False)\n",
    "x.loc[:,'P_SMPB_JNNG_FLG_RE'] =  pd.cut(x['P_SMPB_JNNG_FLG_RE'], 50,labels=False)\n",
    "    \n",
    "test = x.loc[train.shape[0]:].copy()\n",
    "train = x.loc[:train.shape[0]].copy()\n",
    "\n",
    "# Always good to shuffle for SGD type optimizers\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# categories, numerics 분리\n",
    "categories = train.columns[[43,44,45,64,65,66,67,68]]\n",
    "numerics = train.columns[[1,2,3,4,5,6,7,8,9,10,\n",
    "                          11,12,13,14,15,16,17,18,19,20,\n",
    "                          21,22,23,24,25,26,27,28,29,30,\n",
    "                          31,32,33,34,35,36,37,38,39,40,\n",
    "                          41,42,46,47,48,49,50,\n",
    "                          51,52,53,54,55,56,57,58,59,60,\n",
    "                          61,62,63,69,70,\n",
    "                          71,72,73,74,75,76,77,78,79,80,\n",
    "                          81,82,83,84,85,86,87,88,89,90,\n",
    "                          91,92]]\n",
    "# LIBSVM 데이터 포맷 변환\n",
    "currentcode = len(numerics)\n",
    "catdict = {}\n",
    "catcodes = {}\n",
    "for x in numerics:\n",
    "    catdict[x] = 0\n",
    "for x in categories:\n",
    "    catdict[x] = 1\n",
    "\n",
    "noofrows = train.shape[0]\n",
    "noofcolumns = len(features)\n",
    "with open(\"alltrainffm.txt\", \"w\") as text_file:\n",
    "    for n, r in enumerate(range(noofrows)):\n",
    "        datastring = \"\"\n",
    "        datarow = train.iloc[r].to_dict()\n",
    "        datastring += str(int(datarow['TARGET']))\n",
    "\n",
    "\n",
    "        for i, x in enumerate(catdict.keys()):\n",
    "            if(catdict[x]==0):\n",
    "                datastring = datastring + \" \"+str(i)+\":\"+ str(i)+\":\"+ str(datarow[x])\n",
    "            else:\n",
    "                if(x not in catcodes):\n",
    "                    catcodes[x] = {}\n",
    "                    currentcode +=1\n",
    "                    catcodes[x][datarow[x]] = currentcode\n",
    "                elif(datarow[x] not in catcodes[x]):\n",
    "                    currentcode +=1\n",
    "                    catcodes[x][datarow[x]] = currentcode\n",
    "\n",
    "                code = catcodes[x][datarow[x]]\n",
    "                datastring = datastring + \" \"+str(i)+\":\"+ str(int(code))+\":1\"\n",
    "        datastring += '\\n'\n",
    "        text_file.write(datastring)\n",
    "        \n",
    "noofrows = test.shape[0]\n",
    "noofcolumns = len(features)\n",
    "with open(\"alltestffm.txt\", \"w\") as text_file:\n",
    "    for n, r in enumerate(range(noofrows)):\n",
    "        datastring = \"\"\n",
    "        datarow = test.iloc[r].to_dict()\n",
    "        datastring += str(int(datarow['TARGET']))\n",
    "\n",
    "\n",
    "        for i, x in enumerate(catdict.keys()):\n",
    "            if(catdict[x]==0):\n",
    "                datastring = datastring + \" \"+str(i)+\":\"+ str(i)+\":\"+ str(datarow[x])\n",
    "            else:\n",
    "                if(x not in catcodes):\n",
    "                    catcodes[x] = {}\n",
    "                    currentcode +=1\n",
    "                    catcodes[x][datarow[x]] = currentcode\n",
    "                elif(datarow[x] not in catcodes[x]):\n",
    "                    currentcode +=1\n",
    "                    catcodes[x][datarow[x]] = currentcode\n",
    "\n",
    "                code = catcodes[x][datarow[x]]\n",
    "                datastring = datastring + \" \"+str(i)+\":\"+ str(int(code))+\":1\"\n",
    "        datastring += '\\n'\n",
    "        text_file.write(datastring)\n",
    "\n",
    "import xlearn as xl\n",
    "\n",
    "# Training task\n",
    "ffm_model = xl.create_ffm()                # Use field-aware factorization machine (ffm)\n",
    "ffm_model.setTrain(\"./alltrainffm.txt\")    # Set the path of training dataset\n",
    "ffm_model.setValidate(\"./alltestffm.txt\")  # Set the path of validation dataset\n",
    "\n",
    "# Parameters:\n",
    "#  0. task: binary classification\n",
    "#  1. learning rate: 0.2\n",
    "#  2. regular lambda: 0.002\n",
    "#  3. evaluation metric: accuracy\n",
    "param = {'task':'binary', 'lr':0.0005,'lambda':0.00001, 'metric':'auc', 'k':10, 'opt':'sgd'}\n",
    "\n",
    "# Start to train\n",
    "ffm_model.fit(param, './model.out')\n",
    "\n",
    "# Prediction task\n",
    "ffm_model.setTest(\"./alltestffm.txt\")  # Set the path of test dataset\n",
    "ffm_model.setSign()                 # Convert output to 0-1\n",
    "\n",
    "# Start to predict\n",
    "Y_pred1 = ffm_model.predict(\"./model.out\")\n",
    "\n",
    "#성능 평가\n",
    "from sklearn import metrics\n",
    "ffm_accuracy=metrics.accuracy_score(Y_test,Y_pred1)\n",
    "ffm_score=metrics.precision_recall_fscore_support(Y_test,Y_pred1)\n",
    "\n",
    "print('accuracy')\n",
    "print(ffm_accuracy)\n",
    "ffm_score = pd.DataFrame(ffm_score).transpose()\n",
    "ffm_score.columns = [\"precision\", \"recall\", \"fscore\", \"support\"]\n",
    "print(ffm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fd5e7f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.8084548674047015\n",
      "   precision    recall    fscore  support\n",
      "0   0.998128  0.808610  0.893430  35608.0\n",
      "1   0.028372  0.786561  0.054768    253.0\n"
     ]
    }
   ],
   "source": [
    "#샘플링 적용\n",
    "# 데이터 추가 전처리\n",
    "train = pd.concat([Y_smotenc,X_smotenc],axis=1)\n",
    "test = pd.concat([Y_test,X_test],axis=1)\n",
    "x = pd.concat([train,test])\n",
    "x = x.reset_index(drop=True)\n",
    "unwanted = x.columns[x.columns.str.startswith('ps_calc_')]\n",
    "x.drop(unwanted,inplace=True,axis=1)\n",
    "features = x.columns[2:]\n",
    "categories = []\n",
    "for c in features:\n",
    "    trainno = len(x.loc[:train.shape[0],c].unique())\n",
    "    testno = len(x.loc[train.shape[0]:,c].unique())\n",
    "# 카테고리 피쳐 전처리\n",
    "x.loc[:,'J_SIC_CD_5_RE'] = pd.cut(x['J_SIC_CD_5_RE'], 50,labels=False)\n",
    "x.loc[:,'J_SKIL_GDCD_RE'] = pd.cut(x['J_SKIL_GDCD_RE'], 50,labels=False)\n",
    "x.loc[:,'J_MAIN_LON_BANK_CD_RE'] = pd.cut(x['J_MAIN_LON_BANK_CD_RE'], 50,labels=False)\n",
    "x.loc[:,'P_PRIMARY_CUSTOM_FLG_RE'] =  pd.cut(x['P_PRIMARY_CUSTOM_FLG_RE'], 50,labels=False)\n",
    "x.loc[:,'P_ACT_CUSTOM_FLG_RE'] =  pd.cut(x['P_ACT_CUSTOM_FLG_RE'], 50,labels=False)\n",
    "x.loc[:,'P_TOT_LON_FLG_RE'] =  pd.cut(x['P_TOT_LON_FLG_RE'], 50,labels=False)\n",
    "x.loc[:,'P_INBK_JNNG_FLG_RE'] =  pd.cut(x['P_INBK_JNNG_FLG_RE'], 50,labels=False)\n",
    "x.loc[:,'P_SMPB_JNNG_FLG_RE'] =  pd.cut(x['P_SMPB_JNNG_FLG_RE'], 50,labels=False)\n",
    "    \n",
    "test = x.loc[train.shape[0]:].copy()\n",
    "train = x.loc[:train.shape[0]].copy()\n",
    "\n",
    "# Always good to shuffle for SGD type optimizers\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# categories, numerics 분리\n",
    "categories = train.columns[[43,44,45,64,65,66,67,68]]\n",
    "numerics = train.columns[[1,2,3,4,5,6,7,8,9,10,\n",
    "                          11,12,13,14,15,16,17,18,19,20,\n",
    "                          21,22,23,24,25,26,27,28,29,30,\n",
    "                          31,32,33,34,35,36,37,38,39,40,\n",
    "                          41,42,46,47,48,49,50,\n",
    "                          51,52,53,54,55,56,57,58,59,60,\n",
    "                          61,62,63,69,70,\n",
    "                          71,72,73,74,75,76,77,78,79,80,\n",
    "                          81,82,83,84,85,86,87,88,89,90,\n",
    "                          91,92]]\n",
    "# LIBSVM 데이터 포맷 변환\n",
    "currentcode = len(numerics)\n",
    "catdict = {}\n",
    "catcodes = {}\n",
    "for x in numerics:\n",
    "    catdict[x] = 0\n",
    "for x in categories:\n",
    "    catdict[x] = 1\n",
    "\n",
    "noofrows = train.shape[0]\n",
    "noofcolumns = len(features)\n",
    "with open(\"alltrainffm.txt\", \"w\") as text_file:\n",
    "    for n, r in enumerate(range(noofrows)):\n",
    "        datastring = \"\"\n",
    "        datarow = train.iloc[r].to_dict()\n",
    "        datastring += str(int(datarow['TARGET']))\n",
    "\n",
    "\n",
    "        for i, x in enumerate(catdict.keys()):\n",
    "            if(catdict[x]==0):\n",
    "                datastring = datastring + \" \"+str(i)+\":\"+ str(i)+\":\"+ str(datarow[x])\n",
    "            else:\n",
    "                if(x not in catcodes):\n",
    "                    catcodes[x] = {}\n",
    "                    currentcode +=1\n",
    "                    catcodes[x][datarow[x]] = currentcode\n",
    "                elif(datarow[x] not in catcodes[x]):\n",
    "                    currentcode +=1\n",
    "                    catcodes[x][datarow[x]] = currentcode\n",
    "\n",
    "                code = catcodes[x][datarow[x]]\n",
    "                datastring = datastring + \" \"+str(i)+\":\"+ str(int(code))+\":1\"\n",
    "        datastring += '\\n'\n",
    "        text_file.write(datastring)\n",
    "        \n",
    "noofrows = test.shape[0]\n",
    "noofcolumns = len(features)\n",
    "with open(\"alltestffm.txt\", \"w\") as text_file:\n",
    "    for n, r in enumerate(range(noofrows)):\n",
    "        datastring = \"\"\n",
    "        datarow = test.iloc[r].to_dict()\n",
    "        datastring += str(int(datarow['TARGET']))\n",
    "\n",
    "\n",
    "        for i, x in enumerate(catdict.keys()):\n",
    "            if(catdict[x]==0):\n",
    "                datastring = datastring + \" \"+str(i)+\":\"+ str(i)+\":\"+ str(datarow[x])\n",
    "            else:\n",
    "                if(x not in catcodes):\n",
    "                    catcodes[x] = {}\n",
    "                    currentcode +=1\n",
    "                    catcodes[x][datarow[x]] = currentcode\n",
    "                elif(datarow[x] not in catcodes[x]):\n",
    "                    currentcode +=1\n",
    "                    catcodes[x][datarow[x]] = currentcode\n",
    "\n",
    "                code = catcodes[x][datarow[x]]\n",
    "                datastring = datastring + \" \"+str(i)+\":\"+ str(int(code))+\":1\"\n",
    "        datastring += '\\n'\n",
    "        text_file.write(datastring)\n",
    "\n",
    "import xlearn as xl\n",
    "\n",
    "# Training task\n",
    "ffm_model = xl.create_ffm()                # Use field-aware factorization machine (ffm)\n",
    "ffm_model.setTrain(\"./alltrainffm.txt\")    # Set the path of training dataset\n",
    "ffm_model.setValidate(\"./alltestffm.txt\")  # Set the path of validation dataset\n",
    "\n",
    "# Parameters:\n",
    "#  0. task: binary classification\n",
    "#  1. learning rate: 0.2\n",
    "#  2. regular lambda: 0.002\n",
    "#  3. evaluation metric: accuracy\n",
    "param = {'task':'binary', 'lr':0.0005,'lambda':0.00001, 'metric':'auc', 'k':10, 'opt':'sgd'}\n",
    "\n",
    "# Start to train\n",
    "ffm_model.fit(param, './model.out')\n",
    "\n",
    "# Prediction task\n",
    "ffm_model.setTest(\"./alltestffm.txt\")  # Set the path of test dataset\n",
    "ffm_model.setSign()                 # Convert output to 0-1\n",
    "\n",
    "# Start to predict\n",
    "Y_pred1 = ffm_model.predict(\"./model.out\")\n",
    "\n",
    "#성능 평가\n",
    "from sklearn import metrics\n",
    "ffm_accuracy=metrics.accuracy_score(Y_test,Y_pred1)\n",
    "ffm_score=metrics.precision_recall_fscore_support(Y_test,Y_pred1)\n",
    "\n",
    "print('accuracy')\n",
    "print(ffm_accuracy)\n",
    "ffm_score = pd.DataFrame(ffm_score).transpose()\n",
    "ffm_score.columns = [\"precision\", \"recall\", \"fscore\", \"support\"]\n",
    "print(ffm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c3cfc214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic\n",
      "accuracy\n",
      "0.8517609659518697\n",
      "   precision    recall    fscore  support\n",
      "0   0.998519  0.851971  0.919442  35608.0\n",
      "1   0.037963  0.822134  0.072575    253.0 \n",
      "\n",
      "Decision Tree\n",
      "accuracy\n",
      "0.7400239814840635\n",
      "   precision    recall    fscore  support\n",
      "0   0.998861  0.739019  0.849515  35608.0\n",
      "1   0.023434  0.881423  0.045655    253.0 \n",
      "\n",
      "Random Forest\n",
      "accuracy\n",
      "0.8800646942360781\n",
      "   precision    recall    fscore  support\n",
      "0   0.998662  0.880392  0.935805  35608.0\n",
      "1   0.047204  0.833992  0.089350    253.0 \n",
      "\n",
      "MLP with bagging\n",
      "accuracy\n",
      "0.8069769387356739\n",
      "   precision    recall    fscore  support\n",
      "0   0.998263  0.807010  0.892506  35608.0\n",
      "1   0.028693  0.802372  0.055404    253.0 \n",
      "\n",
      "FM\n",
      "accuracy\n",
      "0.8236245503471739\n",
      "   precision    recall    fscore  support\n",
      "0   0.997959  0.824056  0.902709  35608.0\n",
      "1   0.029885  0.762846  0.057518    253.0 \n",
      "\n",
      "FFM\n",
      "accuracy\n",
      "0.8084548674047015\n",
      "   precision    recall    fscore  support\n",
      "0   0.998128  0.808610  0.893430  35608.0\n",
      "1   0.028372  0.786561  0.054768    253.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Logistic')\n",
    "print('accuracy')\n",
    "print(log_accuracy)\n",
    "print(log_score,'\\n')\n",
    "print('Decision Tree')\n",
    "print('accuracy')\n",
    "print(tree_accuracy)\n",
    "print(tree_score,'\\n')\n",
    "print('Random Forest')\n",
    "print('accuracy')\n",
    "print(forest_accuracy)\n",
    "print(forest_score,'\\n')\n",
    "print('MLP with bagging')\n",
    "print('accuracy')\n",
    "print(mlpb_accuracy)\n",
    "print(mlpb_score,'\\n')\n",
    "print('FM')\n",
    "print('accuracy')\n",
    "print(fm_accuracy)\n",
    "print(fm_score, '\\n')\n",
    "print('FFM')\n",
    "print('accuracy')\n",
    "print(ffm_accuracy)\n",
    "print(ffm_score, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543d5703",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
